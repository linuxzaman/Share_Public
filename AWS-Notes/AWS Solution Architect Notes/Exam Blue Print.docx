
google aws certification training

130 Minutes in length
60 questions
Multiple choice
results are  between 100-1000 with a passing score of 720
Aim for 70%
Qualification is valid for 2 years
scenario based questions

===================
History of aws
===================

"Invention requires two things
1. The ability to try a lot of experiments,
2. nto having to live with the collateral damage of failed experiments
"


SQS is decouple components.

======================
AWS Service Overview
======================

AWS Global Infrastructure

A Region is a geographical area. Each Region consist of 2 or more Availability Zones(Data Centers)


Edge Locations(caching content)
    This are endpoints for AWS which are used for caching content. typically this consists of CloudFront, Amazon's content Delivery Network(CDN)
    There are many more Edge locations than regions currently there are over 150 Edge locations

Bread and Butter of Service:
    1.  Security, identity and compliance
            IAM
    2.  Compute
            EC2
            LAMBDA
    3.  Storage
            S3
    4.  Network and content Delivery
            ROUTE53
            VPC
            CloudFront
    5.  Databases
            RDS
            DynamoDB

================
SIGNUP WITH FREE TIER ACCOUNT
================

create an aws ACCOUNT
    email address
    password
    confirm password
    AWS account Name


=============================
*****************IAM*********
=============================

IAM
    IAM allows you to manage users and their level of access to the AWS Console.
    Features:
        Centralised control of your AWS account
        Shared Access to your AWS account
        Granular Permissions
        identity Federation(Facebook,etc)
        Multifactor Authentication
        provide temporary access for users and servcies where necessary
        Allows you to set up your own password rotation policy
        Integrates with many different AWS servcies
        Supports PCI DSS compliance

    Key Terminology for IAM
        1.  users
                End users such as people, employees of an organizations etc.
        2.  Groups
                A collection of users, Each user in the group will inherit the permissions of the group
        3.  Policies
                Policies are made up of documents, called policy documents. These documents are in a format called JSON and they give permissions as to what a user/group/role is able to do.
        4.  Roles
                You create roles and then assign them to AWS Resources

IAM accoutns are global basis.

Exam Tips for IAM
    1.  IAM is universal. it does not apply to regions at this time.
    2.  The "root account" is simply the account created when first setup your aws account. it has complete Admin access.
    3.  New Users have NO permissions when first created.
    4.  New users are assigned ACcess key ID and Secret Access keys when first created.
    5.  These are not the same as a password. you cannot use the Access key id and secret access key to login in to the console. you can use this to access AWS via the APIs and Command Line, however.
    6.  You only get to view these once. if you lose them, you have to regenerate them. so, save them in a secure locations.
    7.  Always setup MFA on your root account.
    8.  you can create and customise your own password rotation Policies.
    9.  Roles are more secure than storing your access key and secret access key on individual EC2 instances.
    10. Roles are easier to manage.
    11. Roles can be assigned to an EC2 instance after it is created using both the console & command line.
    12. Roles are universal -- you can use them in any region

==================================================================================
                    Cloud Watch Billing Alarm
==================================================================================



=======================
        S3  
=======================

    S3 Simple Storage Service
        S3 Provides developers and IT Teams with secure, durable, highly-scalable object storage. S3 is easy to use, with a simple web services interface to store and retrieve an y amount of data from anywhere on the web.
        s3 is a safe place to store your files.
        it is object-based storage.
        The Data is spread across multiple devices and facilities.

    S3-Basics
        *.  S3 is object-based -- ie allows you to upload.
        *.  Files can be from 0 Bytes to 5 TB.
        *.  There is unlimited Storage.
        *.   Files are Stored in Buckets.
        *.  S3 is a universal namespace.
        *.  when you upload a file to S3, you will receive a HTTP 200 Code if the upload was successful.
    S3-Objects
        S3 is Objects based. Think of Objects just as files.
        Objects consist of the following:
            Key
            Value
            Version ID
            Metadata
            Subresources
                Access control lists
                Torrents

    Data Consistency Model for s3
        How does data consistency work for S3?
            Read after Write consistency for PUTS of new Objects
            Eventual Consistency for overwrite PUTS and DELETES

    S3-Guarantees
        Built for 99.99% Availability for the S3 Platform
        Amazon Guarantees 99.99% Availability
        Amazon Guarantees 99.99999999999% durability for S3 information(Remember 11 x 9s

    S3-Features
        Tiered Storage Available
        Lifecycle Management
        Versioning
        Encryption
        MFA Deletes
        Secure your data using Access Control List and Buckets Policies

    S3 Storage Classes
        S3-Standard
            99.99% Availability,durability,stored redundantly across multiple devices in multiple facilities and is designed to sustain the loss of 2 facilities concurrently
        S3-IA(Infrequently Accessed)
            For data that is accessed less frequently, but requires rapid access when needed. Lower fee than S3, but you are charged a retrieve fee.
        S3 One Zone-IA 
            For Where you want a Lower-cost option for Infrequently accessed data, but do not requires the multiple Availability Zone data resilience.
        S3- Intelligent Tiering
            designed to optimize costs by automatically moving data to the most cost-effective access tier,without performance impact or operational overhead
        S3-Glacier
            S3 Glacier is a secure,durable,and low-cost storage class for data archiving. you can reliably store any amount of data at costs that are competitive with or cheaper than on-premises solutions. Retrieval times configurable from minutes to hours
        S3-Glacier Deep Archive
            S3 Glacier Deep Archive is Amazon S3's lowest-cost storage class where a retrieve tiem of 12 hours is acceptable.

    S3-Charges based on
        Storage
        Requests
        Storage Management Pricing
        Data Transfer Pricing
        Transfer Acceleration(CloudFront)
        Cross Region Replication Pricing(high Availability)


    Exam Tips
        Remember that s3 is object based
        files can be from 0 Bytes to 5 TB
        There is unlimited storage
        files are stored in Buckets
        s3 is a universal namespace
        https://s3-eu-west-1.Amazonaws.com/acloudguru
        not suitable to install an operating system on.
        successful uploads will generate a HTTP 200 Status Code
        you can turn on MFS Deletes
        key
        Value
        version id
        Metadata
        Subresources
            access control lists
            Torrents
        Read after wirte consistency for PUTS of new object
        Eventual Consistency for overwrite PUTS and DELETES

    notes: Upon sign-up, new AWS customers receive 5 GB of Amazon S3 Standard storage, 20,000 Get Requests, 2,000 Put Requests, 15GB of data transfer in, and 15GB of data transfer out each month for one year.

    =====================
    S3-Buckets creations
    =====================

        Buckets Names are a universal name space
        Bucket can store objects in regions
        Storage class can be applied at objects level or buckets level
        versioning will allow to have multiple copy of original data.
        you can apply Transfer Acceleration
        we can pulic access settins
        access control list with buckets
        cross oring replication can be done with buckets
        you can set life cyle of objects
        replication of s3 bucket can be done
        upload an object to S3 receive a HTTP 200 Code
        S3,S3-IA,S3-IA(One Zone), Glacier
        control access to buckets using either a buckets ACL or using Buckets Policies

    S3-Security and Encryption:
        by default all buckets are private and access control using Bucket Policies and Access Control lists
        S3 buckets can be conigured to create access logs which log all requests made to the s3 bucket. This can be sent to another bucket and even another bucket in another account

        Encryption in Transit is archived by
            SS/TLS
        Encryption at Rest(Server Side) is archived by
            SSE-S3(aws managed keys)
            SSE-KMS(aws key management service)
            SSE-C(Server side Encryption with customers provided)
            Client side Encryption(encrypt and upload on s3)

    S3-Versioning
        Stores all versions of an object(including all writes and even if you delete an object)
        Great backup tool.
        once enabled, versioning cannot be disabled, only suspended.
        Integrates with Lifecycle rules
        versioning MFA Delete capability, which uses MFA, can be used to provide an additional layer of Security


    S3-Lifecycle Management and Glacier:
        Automates moving your objects between the different storage tiers
        we can set storage transition from stage wise
        delete object after certain period
        can be used in conjunction with versioning
        can be applied to current versions and previous versions

    Cross-Region-Replication:
        versioning must be enabled on both the source and destination buckets
        regions must be unique
        files in an existing bucket are not replicated automatically
        all subsequent updated files will be replicated automatically
        delete markers are not replicated
        deleting individual versions or delete markers will not be replicated
        CORS replication require to enable versioning
        you have to create IAM Roles
        bucket has to be in different regions to replicates
        as soon as we start make changes in bucket will 

    Transfer Acceleration(ACG):
        S3 Transfer Acceleration utilises the CloudFront Edge Network to accelerate your uploads to S3. Instead of uploading directly to your S3 bucket, you can use a distinct URL to upload directly
        to an edge location which will then transfer that file to S3. you will get a distinct URL to upload to

    CloudFront(CDN):
        CDN is a system of distributed servers that deliver webpages and other web content to a user based on the geographic locations of the user, the origin of the webpage, and a content delivery server.

        Key-terminology:
            Edge Location:
                This is the location where content will be cached. This is separate to an AWS Region/Az. its cached for time to live
                Edge locations are not just READ only - you can write to them too.
                You can clear cached objects, but you will be charged.
            origin:
                This is the origin of al lthe files that the CDN will distribute. This can be an S3 Bucket, an EC2 instance, an Elastic Load Balancer, or Route53.
            distribution:
                This is the name given the CDN which consists of a collection of Edge locations
                Types of distribution:
                    Web distribution:- typically used for websites
                    RTMP:- Used for media streaming
    SnowBall:
        snowball is a petabyte-scale data transport solution that uses secure appliances to transfer large amounts of data into and out of AWS.
        Using Snowball addresses common challenges with large-scale data transfers including high network costs, long transfer times, and Security concerns.
        Transferring data with snowball is simple,fast,secure,and can be as little as one-fifth the cost of high-speed internet.            
        Exam Tips:
            Snowball can import to s3 and Export from s3
    SnowballMobile:

        ./snowball start -i 192.168.1.1 -m menifest-file.bin -u menifest-code then enter

        echo "hello world"> hello.txt

        ./snowball cp hello.txt s3://bucket-name then enter
    
    Storage Gateways:****
        File Gate(NFS)
        Volume Gateway:
            Store disk(iscsi)
            Cache disk(frequently used data)
        Tape Volume
        (NetBackup, Backup Exec, Veeam etc)

        Exam Tips:
            File Gateway:
                file gateway -for flat files, stored directly on s3
            Volume Gateway
                Stored Volumes:- Entire Dataset is stored on site and is asynchronously backed up to S3
                Cached Volumes:- Entire Dataset is stored on S3 and the most frequently accessed data is cached on site.
            Gateway Virtual Tape Library

============================================================
***********EC2***********
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
============================================================
EC2
    Amazon Elastic Compute Cloud(EC2) is a web service that provides resiable compute capacity in the Cloud.
    EC2 reduces the time required to obtain and boot new server instances to minutes, allowing you to quickly scale capcity, both up and down as your computing requirements change.
    
    EC2 Pricing Models
        On Demand:
            Allows you to pay a fixed rate by the hour with no commitment.
        Reserved:
            Provides you with a capcity reservation, and offer a significant discount on the hourly charge for an instance. contract Terms are 1 Year or 3 Year Terms
                Reserved Type:
                    Standard REserved instances(75% off)
                    Convertible Reserved Instances(45%)
                    Scheduled Reserved Instances(reserve time and scaling)
        Spot:
            Enables you to bid whatever price you want for instance capacity, providing for even greater savings if your applications have flexible start and end times.
        Dedicated Hosts:
            Physical EC2 server dedicated for your use. Dedicated Hosts can help you reduce costs by allowing you to use your existing server-bound software licenses.
        
    EC2 Instance Types- Mnemonic
    F - For FPGA
    I - For IOPS
    G - GRAPHICS
    H - HIGH DISK THROUGHPUT
    T - CHEAP GENERAL PURPOSE(T2 MICRO)
    D - FOR DENSITY
    R - FOR RAM
    M - MAIN CHOICE FOR GENERAL PURPOSE APPS
    C - FOR COMPUTE
    P - GRAPHICS
    X - EXTREME MEMEORY
    Z - EXTREME MEMEORY AND CPU
    A - ARM BASED WORKLOADS
    U - BARE METAL
    
    EC2- Security Groups:
        All inbound traffic is blocked by default.
        All Outbound traffic is allowed.
        Changes to Security Groups take effect immediately.
        You can have any number of EC2 instances within a security group.
        You can have multiple security groups attached to EC2 Instances.
        Security Groups are STATEFUL.
        If you create an inbound rule allowing Traffic in, that traffic is automatically allowed back out again.
        You cannot block specific IP addresses using security groups, Instead use Network Access Control Lists(NACL)
        You can specify allow rules, but not deny rules.

    
        Exam Tips:
            EC2 is compute capacity Virtual machine in Cloud.
            Termination protection is turned off by default, you must turn it on.
            on an EBS-backed instance, the default action is for the root EBS volume to be deleted when the instance is terminated.
            EBS Root Volumes of your DEFAULT AMI's cannot be encrypted. You can also use a third party tool to encrypt the root volume, or this can be done when creating AMI's in the AWS console or using the API.
            All inbound traffic is blocked by default.
            All Outbound traffic is allowed.
            Changes to Security Groups take effect immediately.
            You can have any number of EC2 instances within a security group.
            You can have multiple security groups attached to EC2 Instances.
            Security Groups are STATEFUL.
            If you create an inbound rule allowing Traffic in, that traffic is automatically allowed back out again.
            You cannot block specific IP addresses using security groups, Instead use Network Access Control Lists(NACL)
            You can specify allow rules, but not deny rules.
            where ever is EC2 instance the EBS volume also stay in same regions

     EBS(Amazon Elastic Block Store):
        EBS provides persistent block storage volumes for use with amazon EC2instances in the AWS Cloud.
        Each Amazon EBS volume is automatically replicated within its Availability Zone to protect you from  components failure, offering high Availability and durability.

        EBS Volume Types:
            GENERAL PURPOSE(SSD)-(most work load,gp2,1GIB- 16TB,16,000)
            PROVISIONED IOPS(SSD)-(Databases,io1,4Gib-16TB,64,000)
            THROUGHPUT OPTIMISED HARD DISK DRIVE-(Big Data and Data warehouses, st1, 500 -16TB,500)
            COLD HARD DISK DRIVE--( File Servers,sc1,500-16TB,250)
            MAGNETIC--(workloads where data is Infrequently accessed, Standard,1Gb-1TB,40-200)

        EBS-SNAPSHOT EXAM TIPS
            volume exists on EBS. Think of EBS as a virtual hard disk
            Snapshots exist on S3. Think of snapshots as a photograph of the disk.
            Snapshots are point in time copies of volumes
            snapshots are incremental --- this means that only the blocks that have changed since your last snapshot are moved to S3.
            if this is your first snapshot, it may take some time to create.
            To create a snapshot for Amazon EBS VolumeS that serve as root devices, you should stop the instance before taking the snapshot.
            However you can take a snap while the instance is running.
            you can create AMI's from both Volumes and snapshots
            you can change EBS Volume sizes on the fly, including changing the size and storage type.
            volumes will Always be in the same Availability Zone as the EC2
            To move an EC2 volume from one AZ to another, take a snapshot of it, create an AMI from the snapshot and then use the AMI to launch the EC2 instance in a new AZ.
            To move an EC2 voluem from one region to another, take a snapshot of it, create an AMI from the snapshot and then copy the AMI from one region to the other. then use the copied AMI to launch the new EC2 instance in the new region
        
        instance AMI TYPES******VERY IMPORTANT

            instance store volumes are sometime called Ephemeral storage.
            instance store volumes cannot be stopped. if the underlying host fails you will lose your data.
            EBS backed instances can be stopped. you will not lose the data on this instance if it is stopped.
            you can reboot both, you will not lose your data.
            By default, both ROOT volumes will be deleted on termination. However, with EBS volumes, you can tell AWS to keep the root device volume

        Encrypted Root Device Volumes & Snapshots
            snapshots of encrypted volumes are encrypted automatically
            volumes restored from encrypted snapshots are encrypted automatically
            you can share snapshots, but only if they are unencryted
            These snapshots can be shared with other AWS accounts or made public.
            create a snapshot of the unencryted root device volume
            create a copy of the snapshot and select the encrypt option
            create an ami from the encrypted snapshot
            use that ami to launch new encrypted Instances

    CloudWatch
        Amazon CloudWatch is a monitoring service to monitor your AWS resources, as well as the applications that you run on AWS.
        CloudWatch monitor performance.
        monitoring:
            Compute
                EC2 Instances
                Autoscaling Groups
                Elastic Load Balancers
                Route53 Health Checks
            Storage & Content Delivery
                EBS Volumes
                Storage Gateways
                CloudFront
            Host level metrics consist of:
                CPU
                Network
                disk
                Status Check
        AWS CloudTrail increases visibility into your user and resources activity by recording AWS management console actions and API calls. You can identity which users and accounts called AWS, the source IP address from which the calls were made, and when the calls occurred.
        Exam Tips:
            CloudWatch with ec2 will monitor events every 1 and 5 minutes detailed monitoring.
            CloudWatch is all about performance.
            CloudTrail is all about auditing or monitor API calls in the AWS Platform.
            Dashboards -creates awesome dashboards to see what is happening with your AWS enviroment.
            Alarms - Allows you to set Alarms that notify you when particular thresholds are hit.
            Events -  Cloudwatch events helps you to respond to state changes in your AWS resources.
            Logs - Cloudwatch logs helps you to aggregate, monitor, and store logs.

    Instance Metadata
        curl http://169.254.169.254/latest/user-data ( TO GET BOOTSTRAP DATA)
        curl http://169.254.169.254/latest/meta-data ( TO GET meta-deta)

        EXAM-TIPS
            used to get Information about an instance such as public IP
    
    Elastic File SYSTEM:
        Amazon EFS is a file storage service for EC2instances. 
        Amazon EFS is easy to use and provides a simple interface that allows you to create and configure file systems quickly and easily.
        With amazon EFS, Storage capcity is elastic, growing and shrinking automatically as you add and remove files, so your applications have the storage they need,when they need it.

        Exam Tips:
            supports the NFS4 protocol
            you only pay for the storage you use
            can scale up to the petabyte
            can suport thousands of concurrent NFS connections
            Data is stored across multiple AZ's within a region
            Read After Write Consistency
    
    EC2 PLACEMENT GROUP:
        Clustered Placement Group:
            A cluster placement group is a grouping of instances within a single Availability Zone.
            Placement groups are recommended for applications that need low network latency, high network throughput, or both.
            Only certain instances can be launched in to a Clustered placement group.
        
        Spread Placement Group:
            A spread placement group is a group of instances that are each placed on distinct underlying hardware.
            Spread Placement groups are recommended for applications that have a small number of critical instances that should be kept separate from each other.
        
        Exam Tips:
            A clustered placement group can't span multiple Availability zones.
            a spread placement group can.
            The name you specify for a placement group must be unique within your AWS account.
            Only certain types of instances can be launched in a placement group(Compute Optimized, GPU, Memory Optimized, Storage Optimized)
            AWS  recommended homogenous instances within placement groups
            you can't merge placement groups
            you can't move an existing instance into a placement group. you can create an AMI from your existing instance, and then launch a new instance from the AMI into a placement group.
        





    

    







